{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8FI3Mex94K_9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "new_path =os.path.join(os.getcwd(),'detected_images\\\\')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 64\n",
        "img_width = 48\n",
        "img_height = 48\n",
        "path = os.getcwd()\n",
        "\n",
        "# print(\"Train : \",train_dir)\n",
        "# print(\"Val : \",val_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stop_cuda():\n",
        "    from numba import cuda \n",
        "    device = cuda.get_current_device()\n",
        "    device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "config=tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess=tf.compat.v1.Session(config=config)\n",
        "print(tf.test.is_built_with_cuda())\n",
        "print(tf.config.list_physical_devices('GPU')) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
        "emotions={0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jXyqxc4E6kwx"
      },
      "outputs": [],
      "source": [
        "def MyRec(rgb,x,y,w,h,v=20,color=(200,0,0),thikness =2):\n",
        "    \"\"\"To draw stylish rectangle around the objects\"\"\"\n",
        "    cv2.line(rgb, (x,y),(x+v,y), color, thikness)\n",
        "    cv2.line(rgb, (x,y),(x,y+v), color, thikness)\n",
        "\n",
        "    cv2.line(rgb, (x+w,y),(x+w-v,y), color, thikness)\n",
        "    cv2.line(rgb, (x+w,y),(x+w,y+v), color, thikness)\n",
        "\n",
        "    cv2.line(rgb, (x,y+h),(x,y+h-v), color, thikness)\n",
        "    cv2.line(rgb, (x,y+h),(x+v,y+h), color, thikness)\n",
        "\n",
        "    cv2.line(rgb, (x+w,y+h),(x+w,y+h-v), color, thikness)\n",
        "    cv2.line(rgb, (x+w,y+h),(x+w-v,y+h), color, thikness)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XdFhFOhY6pRK"
      },
      "outputs": [],
      "source": [
        "def save(img,name, bbox, width=180,height=227):\n",
        "    x, y, w, h = bbox\n",
        "    imgCrop = img[y:h, x: w]\n",
        "    imgCrop = cv2.resize(imgCrop, (width, height))\n",
        "    cv2.imwrite(name+\".jpg\", imgCrop)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nJUtwAXe6pAq"
      },
      "outputs": [],
      "source": [
        "def faces(imagepath):\n",
        "    frame =cv2.imread(imagepath)\n",
        "    gray =cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "    faces = detector(gray)\n",
        "    fit =20\n",
        "    # detect the face\n",
        "    for counter,face in enumerate(faces):\n",
        "        count=counter\n",
        "        x1, y1 = face.left(), face.top()\n",
        "        x2, y2 = face.right(), face.bottom()\n",
        "        cv2.rectangle(frame,(x1,y1),(x2,y2),(220,255,220),1)\n",
        "        MyRec(frame, x1, y1, x2 - x1, y2 - y1, 10, (0,250,0), 3)\n",
        "        # save(gray,new_path+str(counter),(x1-fit,y1-fit,x2+fit,y2+fit))\n",
        "        save(gray,new_path+str(counter),(x1,y1,x2,y2))\n",
        "    frame = cv2.resize(frame,(800,800))\n",
        "    cv2.imshow('Group-Face Detection',frame)\n",
        "    cv2.waitKey(0)\n",
        "    return count+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset(img_folder):\n",
        "\n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "\n",
        "    for file in os.listdir(os.path.join(img_folder)):\n",
        "\n",
        "        image_path= os.path.join(img_folder, file)\n",
        "        image= cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        image=cv2.resize(image, (img_height, img_width))\n",
        "        image=np.array(image)\n",
        "        image = image.astype('float32')\n",
        "        image /= 255 \n",
        "        img_data_array.append(np.reshape(image,(-1,48,48,1)))\n",
        "        # class_name.append(dir1)\n",
        "    return img_data_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same',input_shape=(img_height,img_width,1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.3))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "emotion_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.3))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))\n",
        "################################################################################\n",
        "emotion_model.load_weights(os.path.join(os.getcwd(),'Models/adagram_weights/emotion-reg-weight-0.8965796828269958.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "ooUx4LQJ6uJ0",
        "outputId": "3b9a839d-d40d-48eb-fb03-958600c44c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
            "File :  img4.jpg Has  7 Faces.\n",
            "Found 0 images belonging to 0 classes.\n",
            "{0: 1, 4: 3, 3: 2, 5: 1}\n",
            "{'angry': 14.285714285714285, 'neutral': 42.857142857142854, 'happy': 28.57142857142857, 'sad': 14.285714285714285}\n",
            "The environment looks neutral  :  42.857142857142854\n"
          ]
        }
      ],
      "source": [
        "# count=faces(os.path.join(os.getcwd(),'images','images.jpeg'))\n",
        "print(emotions)\n",
        "for i in os.listdir(os.path.join(os.getcwd(),'images')):\n",
        "    count=faces(os.path.join(os.getcwd(),'images',i))\n",
        "    print(\"File : \",i,\"Has \",count, \"Faces.\")\n",
        "\n",
        "    # read the images\n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        os.path.join(os.getcwd(),'detected_images'),\n",
        "        target_size=(img_width,img_height),\n",
        "        class_mode='categorical')\n",
        "\n",
        "    img_data_array = create_dataset(os.path.join(os.getcwd(),'detected_images'))\n",
        "\n",
        "    output=[]\n",
        "    for i in range(0,count):\n",
        "        output.append(np.argmax(emotion_model.predict(img_data_array[i])))\n",
        "\n",
        "\n",
        "    resultant_dict=dict()\n",
        "    for i in output:\n",
        "        if i not in resultant_dict:\n",
        "            resultant_dict[i]=1\n",
        "        else:\n",
        "            resultant_dict[i]+=1  \n",
        "    print(resultant_dict)\n",
        "\n",
        "    for i in os.listdir(new_path):\n",
        "        os.remove(os.path.join(os.getcwd(),'detected_images',i))\n",
        "\n",
        "    probability={}\n",
        "    for emotion,no_of_persons_emotion in resultant_dict.items():\n",
        "        probability[emotions[emotion]]=(no_of_persons_emotion/count)*100\n",
        "    print(probability)\n",
        "    environment_situation=max(probability, key=probability.get)\n",
        "    print(\"The environment looks\",environment_situation,\" : \",probability[environment_situation])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "extract_faces_and _save.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "830f0125b009c1ba3feaab44ce764bea97d81b327b5bd7e84564a80c83019ea2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
